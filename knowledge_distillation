import bit_pytorch.train as train
import torch
import bit_pytorch.models as models
import argparse
import bit_hyperrule
import bit_common
import numpy as np
import bit_pytorch.lbtoolbox as lb



def argparser(known_models):
  parser = argparse.ArgumentParser(description="Knowledge distillation")
  parser.add_argument("--model_teacher", choices=list(known_models),
                      help="Which variant to use; BiT-M gives best results.")
  parser.add_argument("--model_student", choices=list(known_models),
                      help="Which variant to use; BiT-M gives best results.")
  parser.add_argument("--dataset", choices=list(bit_hyperrule.known_dataset_sizes.keys()),
                      help="Choose the dataset. It should be easy to add your own! "
                      "Don't forget to set --datadir if necessary.")
  parser.add_argument("--logdir", required=True,
                      help="Where to log training info (small).")
  parser.add_argument("--name", required=True,
                      help="Name of this run. Used for monitoring and checkpointing.")
  parser.add_argument("--finetuned", required=True,
                      help="Where to search for finetuned BiT models.")
  parser.add_argument("--batch", type=int, default=512,
                      help="Batch size.")
  parser.add_argument("--batch_split", type=int, default=1,
                      help="Number of batches to compute gradient on before updating weights.")
  parser.add_argument("--examples_per_class", type=int, default=None,
                      help="For the few-shot variant, use this many examples "
                      "per class only.")
  return parser

def main(args):
    logger = logger = bit_common.setup_logger(args)
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    chrono = lb.Chrono()

    logger.info(f"Loading model from {args.finetuned}")
    train_set, valid_set, train_loader, valid_loader = train.mktrainval(args, logger)
    teacher = models.KNOWN_MODELS[args.model_teacher](head_size=len(valid_set.classes), zero_head=True)

    logger.info("Moving teacher model onto all GPUs")
    teacher = torch.nn.DataParallel(teacher)

    checkpoint = torch.load(args.finetuned, map_location="cpu")
    logger.info(f"Found saved model to resume from at '{args.finetuned}'")

    step = checkpoint["step"]
    logger.info(f"Resumed at step {step}")
    teacher.load_state_dict(checkpoint["model"])

    teacher = teacher.to(device)
    train.run_eval(teacher, valid_loader, device, chrono, logger, step='end')

    student = models.KNOWN_MODELS[args.model_student](head_size=len(valid_set.classes), zero_head=True)

    logger.info("Moving student model onto all GPUs")
    student = torch.nn.DataParallel(student)

    student = student.to(device)
    train.run_eval(student, valid_loader, device, chrono, logger, step='end')
    

if __name__ == "__main__":
  parser = argparser(models.KNOWN_MODELS.keys())
  parser.add_argument("--datadir", required=True,
                      help="Path to the ImageNet data folder, preprocessed for torchvision.")
  parser.add_argument("--workers", type=int, default=8,
                      help="Number of background threads used to load data.")
  parser.add_argument("--no-save", dest="save", action="store_false")
  main(parser.parse_args())