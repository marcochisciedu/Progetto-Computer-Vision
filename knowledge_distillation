import bit_pytorch.train as train
import torch
import bit_pytorch.models as models
import argparse
import bit_hyperrule
import bit_common
import numpy as np
import bit_pytorch.lbtoolbox as lb



def argparser(known_models):
  parser = argparse.ArgumentParser(description="Knowledge distillation")
  parser.add_argument("--model", choices=list(known_models),
                      help="Which variant to use; BiT-M gives best results.")
  parser.add_argument("--dataset", choices=list(bit_hyperrule.known_dataset_sizes.keys()),
                      help="Choose the dataset. It should be easy to add your own! "
                      "Don't forget to set --datadir if necessary.")
  parser.add_argument("--logdir", required=True,
                      help="Where to log training info (small).")
  parser.add_argument("--name", required=True,
                      help="Name of this run. Used for monitoring and checkpointing.")
  parser.add_argument("--finetuned", required=True,
                      help="Where to search for finetuned BiT models.")
  
  return parser

def main(args):
    logger = logger = bit_common.setup_logger(args)
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    chrono = lb.Chrono()

    logger.info(f"Loading model from {args.finetuned}")
    train_set, valid_set, train_loader, valid_loader = train.mktrainval(args, logger)
    model = models.KNOWN_MODELS[args.model](head_size=len(valid_set.classes), zero_head=True)
    checkpoint = torch.load(args.finetuned, map_location="cpu")

    step = checkpoint["step"]
    model.load_state_dict(checkpoint["model"])
    logger.info(f"Resumed at step {step}")

    logger.info("Moving model onto all GPUs")
    model = torch.nn.DataParallel(model)

    model = model.to(device)
    train.run_eval(model, valid_loader, device, chrono, logger, step='end')

if __name__ == "__main__":
  parser = argparser(models.KNOWN_MODELS.keys())
  parser.add_argument("--datadir", required=True,
                      help="Path to the ImageNet data folder, preprocessed for torchvision.")
  parser.add_argument("--workers", type=int, default=8,
                      help="Number of background threads used to load data.")
  parser.add_argument("--no-save", dest="save", action="store_false")
  main(parser.parse_args())