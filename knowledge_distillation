import bit_pytorch.train as train
import torch
import bit_pytorch.models as models
import argparse
import bit_hyperrule
import bit_common
import numpy as np
import bit_pytorch.lbtoolbox as lb
import matplotlib.pyplot as plt
import torchvision as tv
from os.path import join as pjoin 


def argparser(known_models):
  parser = argparse.ArgumentParser(description="Knowledge distillation")
  parser.add_argument("--model_teacher", choices=list(known_models),
                      help="Which variant to use; BiT-M gives best results.")
  parser.add_argument("--model_student", choices=list(known_models),
                      help="Which variant to use; BiT-M gives best results.")
  parser.add_argument("--dataset", choices=list(bit_hyperrule.known_dataset_sizes.keys()),
                      help="Choose the dataset. It should be easy to add your own! "
                      "Don't forget to set --datadir if necessary.")
  parser.add_argument("--logdir", required=True,
                      help="Where to log training info (small).")
  parser.add_argument("--name", required=True,
                      help="Name of this run. Used for monitoring and checkpointing.")
  parser.add_argument("--finetuned", required=True,
                      help="Where to search for finetuned BiT models.")
  parser.add_argument("--batch", type=int, default=512,
                      help="Batch size.")
  parser.add_argument("--epochs", type=int, default=300,
                      help="Epochs")
  parser.add_argument("--temperature", type=int, default=2,
                      help="temperature")
  parser.add_argument("--weight_decay", type=float, default=1e-5,
                      help="weight decay")
  parser.add_argument("--clip_threshold", type=float, default=1,
                      help="clip threshold")
  parser.add_argument("--base_lr", type=float, default=0.001,
                      help="Base learning-rate.")
  parser.add_argument("--batch_split", type=int, default=1,
                      help="Number of batches to compute gradient on before updating weights.")
  return parser

def mixup(images, labels):
    alpha = torch.rand(1)
    mixedup_images = (alpha * images +
                     (1 - alpha) * torch.flip(images, dims=[0]))
    return mixedup_images, labels

def get_datasets(args, logger):
  """Returns train and validation datasets."""
  precrop, crop = bit_hyperrule.get_resolution_from_dataset(args.dataset)       #con nuovi dataset protebbero cambiare questi
  train_tx = tv.transforms.Compose([
      tv.transforms.Resize((precrop, precrop)),
      tv.transforms.RandomCrop((crop, crop)),
      tv.transforms.RandomHorizontalFlip(),
      tv.transforms.ToTensor(),
  ])
  val_tx = tv.transforms.Compose([
      tv.transforms.Resize((crop, crop)),
      tv.transforms.ToTensor(),
  ])

  if args.dataset == "cifar10":
    train_set = tv.datasets.CIFAR10(args.datadir, transform=train_tx, train=True, download=True)
    valid_set = tv.datasets.CIFAR10(args.datadir, transform=val_tx, train=False, download=True)
  elif args.dataset == "cifar100":
    train_set = tv.datasets.CIFAR100(args.datadir, transform=train_tx, train=True, download=True)
    valid_set = tv.datasets.CIFAR100(args.datadir, transform=val_tx, train=False, download=True)
  elif args.dataset == "imagenet2012":
    train_set = tv.datasets.ImageFolder(pjoin(args.datadir, "train"), train_tx)
    valid_set = tv.datasets.ImageFolder(pjoin(args.datadir, "val"), val_tx)
  else:
    raise ValueError(f"Sorry, we have not spent time implementing the "
                     f"{args.dataset} dataset in the PyTorch codebase. "
                     f"In principle, it should be easy to add :)")

  logger.info(f"Using a training set with {len(train_set)} images.")
  logger.info(f"Using a validation set with {len(valid_set)} images.")

  micro_batch_size = args.batch // args.batch_split

  valid_loader = torch.utils.data.DataLoader(
      valid_set, batch_size=micro_batch_size, shuffle=False,
      num_workers=args.workers, pin_memory=True, drop_last=False)

  if micro_batch_size <= len(train_set):
    train_loader = torch.utils.data.DataLoader(
        train_set, batch_size=micro_batch_size, shuffle=True,
        num_workers=args.workers, pin_memory=True, drop_last=False)
  else:
    # In the few-shot cases, the total dataset size might be smaller than the batch-size.
    # In these cases, the default sampler doesn't repeat, so we need to make it do that
    # if we want to match the behaviour from the paper.
    train_loader = torch.utils.data.DataLoader(
        train_set, batch_size=micro_batch_size, num_workers=args.workers, pin_memory=True,
        sampler=torch.utils.data.RandomSampler(train_set, replacement=True, num_samples=micro_batch_size))

  return train_set, valid_set, train_loader, valid_loader

def main(args):
    logger = logger = bit_common.setup_logger(args)
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    chrono = lb.Chrono()

    train_set, valid_set, train_loader, valid_loader = get_datasets(args, logger)

    logger.info(f"Visualising some images of the dataset in dataset.png")
    sample_images, sample_labels = next(iter(train_loader))
    mixed_up_images, _ = mixup(sample_images, sample_labels)
    plt.figure(figsize=(10, 10))
    for n in range(25):
        ax = plt.subplot(5, 5, n + 1)
        plt.imshow(mixed_up_images[n].squeeze().permute(1,2,0))
        plt.axis("off")
    plt.show()
    plt.savefig('dataset.png')

    teacher = models.KNOWN_MODELS[args.model_teacher](head_size=len(valid_set.classes), zero_head=True)

    logger.info("Moving teacher model onto all GPUs")
    teacher = torch.nn.DataParallel(teacher, device_ids=[0])    #da cambiare nel codice finale i dataset piÃ¹ grandi?

    logger.info(f"Loading teacher model from {args.finetuned}")
    checkpoint = torch.load(args.finetuned, map_location="cpu")
    teacher.load_state_dict(checkpoint["model"])

    teacher = teacher.to(device)
    #train.run_eval(teacher, valid_loader, device, chrono, logger, step='end')   #validating teacher model

    student = models.KNOWN_MODELS[args.model_student](head_size=len(valid_set.classes), zero_head=True)

    logger.info("Moving student model onto all GPUs")
    student = torch.nn.DataParallel(student, device_ids=[0])

    #durante l'algoritmo ricordarsi di fare il mixup dei dati prima di usarli

    #validating student model
    student = student.to(device)
    #train.run_eval(student, valid_loader, device, chrono, logger, step='end')
    

if __name__ == "__main__":
  parser = argparser(models.KNOWN_MODELS.keys())
  parser.add_argument("--datadir", required=True,
                      help="Path to the ImageNet data folder, preprocessed for torchvision.")
  parser.add_argument("--workers", type=int, default=8,
                      help="Number of background threads used to load data.")
  parser.add_argument("--no-save", dest="save", action="store_false")
  main(parser.parse_args())